{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blockchainrelativity/Colab_Experiments/blob/main/OpenAI_Assistants_API_Streaming_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install and Configure OpenAI Client"
      ],
      "metadata": {
        "id": "1NYyVrk0YBdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "1xbCxpflX_iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from getpass import getpass\n",
        "client = OpenAI(api_key=getpass(\"Your OpenAI Key: \"), timeout=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WH23-bYbpCK",
        "outputId": "f62bd01b-163b-41b6-d2cb-aa3323ace809"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your OpenAI Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat Completions API Example\n",
        "https://cookbook.openai.com/examples/how_to_stream_completions"
      ],
      "metadata": {
        "id": "hw3QLwKLbjFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {'role': 'user', 'content': \"What's 1+1? Answer in one word.\"}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    stream=True\n",
        ")"
      ],
      "metadata": {
        "id": "cASFF9zebiv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in response:\n",
        "    # print(chunk)\n",
        "    print(chunk.choices[0].delta.content)\n",
        "    print(\"****************\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT8ZB6ksbsUZ",
        "outputId": "18423e8d-d6e1-423b-b661-203f6463dada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "****************\n",
            "2\n",
            "****************\n",
            "None\n",
            "****************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assistants API Example\n",
        "https://platform.openai.com/docs/assistants/overview?context=with-streaming"
      ],
      "metadata": {
        "id": "yZjj7DchkfPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Create an Assistant\n",
        "An Assistant represents an entity that can be configured to respond to a user's messages using several parameters like model, instructions, and tools."
      ],
      "metadata": {
        "id": "AktE93q5YUPd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IShwrC4iW2Tk",
        "outputId": "1659f077-f007-4ae6-fb02-8c835044c97b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your OpenAI Key: ··········\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "assistant = client.beta.assistants.create(\n",
        "  name=\"Math Tutor\",\n",
        "  instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
        "  tools=[{\"type\": \"code_interpreter\"}],\n",
        "  model=\"gpt-4-turbo-preview\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Create a Thread\n",
        "A Thread represents a conversation between a user and one or many Assistants. You can create a Thread when a user (or your AI application) starts a conversation with your Assistant."
      ],
      "metadata": {
        "id": "50IH5U4aY88w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread = client.beta.threads.create()"
      ],
      "metadata": {
        "id": "waXmGHvEY8hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Add a Message to the Thread\n",
        "The contents of the messages your users or applications create are added as Message objects to the Thread. Messages can contain both text and files. There is no limit to the number of Messages you can add to Threads — we smartly truncate any context that does not fit into the model's context window."
      ],
      "metadata": {
        "id": "FLvZhTMiZCx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
        ")"
      ],
      "metadata": {
        "id": "9w4GR463Yjic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Create a Run\n",
        "Once all the user Messages have been added to the Thread, you can Run the Thread with any Assistant. Creating a Run uses the model and tools associated with the Assistant to generate a response. These responses are added to the Thread as assistant Messages."
      ],
      "metadata": {
        "id": "Qba22LSsZXmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import override\n",
        "from openai import AssistantEventHandler\n",
        "\n",
        "# First, we create a EventHandler class to define\n",
        "# how we want to handle the events in the response stream.\n",
        "\n",
        "class EventHandler(AssistantEventHandler):\n",
        "  @override\n",
        "  def on_text_created(self, text) -> None:\n",
        "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
        "\n",
        "  @override\n",
        "  def on_text_delta(self, delta, snapshot):\n",
        "    print(delta.value, end=\"\", flush=True)\n",
        "\n",
        "  def on_tool_call_created(self, tool_call):\n",
        "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
        "\n",
        "  def on_tool_call_delta(self, delta, snapshot):\n",
        "    if delta.type == 'code_interpreter':\n",
        "      if delta.code_interpreter.input:\n",
        "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
        "      if delta.code_interpreter.outputs:\n",
        "        print(f\"\\n\\noutput >\", flush=True)\n",
        "        for output in delta.code_interpreter.outputs:\n",
        "          if output.type == \"logs\":\n",
        "            print(f\"\\n{output.logs}\", flush=True)\n",
        "\n",
        "# Then, we use the `create_and_stream` SDK helper\n",
        "# with the `EventHandler` class to create the Run\n",
        "# and stream the response.\n",
        "\n",
        "with client.beta.threads.runs.create_and_stream(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
        "  event_handler=EventHandler(),\n",
        ") as stream:\n",
        "  stream.until_done()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2yeMB8jZJbE",
        "outputId": "c5cb9eee-9132-476c-c957-0d28cb421bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "assistant > code_interpreter\n",
            "\n",
            "from sympy import symbols, Eq, solve\n",
            "\n",
            "# Define the symbol\n",
            "x = symbols('x')\n",
            "\n",
            "# Define the equation\n",
            "equation = Eq(3*x + 11, 14)\n",
            "\n",
            "# Solve the equation\n",
            "solution = solve(equation, x)\n",
            "\n",
            "solution\n",
            "\n",
            "output >\n",
            "\n",
            "[1]\n",
            "\n",
            "assistant > The solution to the equation \\(3x + 11 = 14\\) is \\(x = 1\\)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example with Custom Functions"
      ],
      "metadata": {
        "id": "OqpFIGevkkmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Create assistant with custom tools"
      ],
      "metadata": {
        "id": "8RasXMxHgvur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  instructions=\"You are a weather bot. Use the provided functions to answer questions.\",\n",
        "  model=\"gpt-4-turbo-preview\",\n",
        "  tools=[{\n",
        "      \"type\": \"function\",\n",
        "    \"function\": {\n",
        "      \"name\": \"getCurrentWeather\",\n",
        "      \"description\": \"Get the weather in location\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
        "          \"unit\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}\n",
        "        },\n",
        "        \"required\": [\"location\"]\n",
        "      }\n",
        "    }\n",
        "  }, {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "      \"name\": \"getNickname\",\n",
        "      \"description\": \"Get the nickname of a city\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
        "        },\n",
        "        \"required\": [\"location\"]\n",
        "      }\n",
        "    }\n",
        "  }]\n",
        ")"
      ],
      "metadata": {
        "id": "Unka8G_2kj1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Create a thread"
      ],
      "metadata": {
        "id": "NUsFPKq-hWSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread = client.beta.threads.create()"
      ],
      "metadata": {
        "id": "QY-exFRDnEqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Add message to thread"
      ],
      "metadata": {
        "id": "U70_o1YagyRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"Check weather in New York and get nickname of this city.\"\n",
        ")"
      ],
      "metadata": {
        "id": "cQNpPEjEhZ2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Run thread"
      ],
      "metadata": {
        "id": "vUJdNxplg6y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import override\n",
        "from openai import AssistantEventHandler\n",
        "import asyncio\n",
        "\n",
        "# First, we create a EventHandler class to define\n",
        "# how we want to handle the events in the response stream.\n",
        "\n",
        "class EventHandler(AssistantEventHandler):\n",
        "  tool_outputs = []\n",
        "  @override\n",
        "  def on_text_created(self, text) -> None:\n",
        "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
        "\n",
        "  @override\n",
        "  def on_text_delta(self, delta, snapshot):\n",
        "    print(delta.value, end=\"\", flush=True)\n",
        "\n",
        "  def on_tool_call_created(self, tool_call):\n",
        "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
        "\n",
        "  def on_tool_call_delta(self, delta, snapshot):\n",
        "    if delta.type == 'code_interpreter':\n",
        "      if delta.code_interpreter.input:\n",
        "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
        "      if delta.code_interpreter.outputs:\n",
        "        print(f\"\\n\\noutput >\", flush=True)\n",
        "        for output in delta.code_interpreter.outputs:\n",
        "          if output.type == \"logs\":\n",
        "            print(f\"\\n{output.logs}\", flush=True)\n",
        "\n",
        "  # def on_tool_call_done(self, tool_call: ToolCall) -> None:\n",
        "  #   if tool_call.function.name == \"getCurrentWeather\":\n",
        "  #     self.tool_outputs.append({\"tool_call_id\": tool_call.id, \"output\": \"The weather is 75 degrees.\"})\n",
        "\n",
        "\n",
        "run = None\n",
        "\n",
        "with client.beta.threads.runs.create_and_stream(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        "  event_handler=EventHandler(),\n",
        ") as stream:\n",
        "  stream.until_done()\n",
        "  run = stream.get_final_run()"
      ],
      "metadata": {
        "id": "4SJVxlnHlmoz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a388cbab-bd7c-410f-8f86-0aecf4d4ae6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "assistant > function\n",
            "\n",
            "\n",
            "assistant > function\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Get tool outputs"
      ],
      "metadata": {
        "id": "Y4cOyYw3i1K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
        "tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9txK4DqiLQp",
        "outputId": "e4ca43b7-102b-4c50-e13f-5716e947ec8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[RequiredActionFunctionToolCall(id='call_LzUxIWb0RmUjjkJ3v1QtJk4V', function=Function(arguments='{\"location\": \"New York, NY\", \"unit\": \"f\"}', name='getCurrentWeather'), type='function'),\n",
              " RequiredActionFunctionToolCall(id='call_1co91yJSr69bHAnb4NCelOof', function=Function(arguments='{\"location\": \"New York, NY\"}', name='getNickname'), type='function')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_outputs = []\n",
        "for tool_call in tool_calls:\n",
        "    if tool_call.function.name == \"getCurrentWeather\":\n",
        "        tool_outputs.append({\"tool_call_id\": tool_call.id, \"output\": \"The weather is 75 degrees\"})\n",
        "    if tool_call.function.name == \"getNickname\":\n",
        "        tool_outputs.append({\"tool_call_id\": tool_call.id, \"output\": \"The big apple\"})"
      ],
      "metadata": {
        "id": "rDkN2FDSiW4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Submit Tool Outputs"
      ],
      "metadata": {
        "id": "yBF0w75yi5h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with client.beta.threads.runs.submit_tool_outputs_stream(\n",
        "        thread_id=thread.id,\n",
        "        run_id=run.id,\n",
        "        tool_outputs=tool_outputs,\n",
        "        event_handler=EventHandler()\n",
        ") as stream:\n",
        "    stream.until_done()"
      ],
      "metadata": {
        "id": "XQKo-d5ouIDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555b370a-2069-4e9c-d73c-aa34d4320318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "assistant > The current weather in New York, NY, is 75 degrees Fahrenheit, and the city's nickname is \"The Big Apple.\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agency Swarm Implementation.\n",
        "\n",
        "Fore more details, see: https://vrsen.github.io/agency-swarm/advanced-usage/agencies/#streaming-responses"
      ],
      "metadata": {
        "id": "8bZ4-yY1k170"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Agency Swarm"
      ],
      "metadata": {
        "id": "rl_ShrCjr5XQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/VRSEN/agency-swarm.git gradio"
      ],
      "metadata": {
        "id": "YEUIC_DTr7Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm import set_openai_client\n",
        "set_openai_client(client)"
      ],
      "metadata": {
        "id": "eDVDeQpVskdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Define your tools.\n",
        "Use `BaseTool` with your logic inside"
      ],
      "metadata": {
        "id": "XXZ8Ez1Sr9F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm.tools import BaseTool\n",
        "from pydantic import Field\n",
        "\n",
        "class GetCurrentWeather(BaseTool):\n",
        "    \"\"\"\n",
        "    Get the weather in a specified location.\n",
        "    \"\"\"\n",
        "    location: str = Field(\n",
        "        ..., description=\"The city and state e.g. San Francisco, CA\"\n",
        "    )\n",
        "    unit: str = Field(\n",
        "        default=\"f\", description=\"The unit of temperature (c for Celsius, f for Fahrenheit)\"\n",
        "    )\n",
        "\n",
        "    def run(self) -> str:\n",
        "        \"\"\"\n",
        "        Return a fixed temperature of 75 degrees Fahrenheit.\n",
        "        \"\"\"\n",
        "        return \"75 degrees\"\n",
        "\n",
        "class GetNickname(BaseTool):\n",
        "    \"\"\"\n",
        "    Get the nickname of a city.\n",
        "    \"\"\"\n",
        "    location: str = Field(\n",
        "        ..., description=\"The city and state e.g. San Francisco, CA\"\n",
        "    )\n",
        "\n",
        "    def run(self) -> str:\n",
        "        \"\"\"\n",
        "        Return \"The Big Apple\" as the nickname.\n",
        "        \"\"\"\n",
        "        return \"The Big Apple\"\n"
      ],
      "metadata": {
        "id": "ayrts6EBrsvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Create your Agent\n",
        "Most of the properties are basically the same, with a few additional ones like `files_folder` to simplify the agent creation process"
      ],
      "metadata": {
        "id": "iqAKnFNysMpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm import Agency, Agent\n",
        "\n",
        "agent = Agent(\n",
        "      instructions=\"You are a weather bot. Use the provided functions to answer questions.\",\n",
        "      model=\"gpt-4-turbo-preview\",\n",
        "      tools=[GetCurrentWeather, GetNickname]\n",
        ")"
      ],
      "metadata": {
        "id": "VW7xZJkXq94K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Initialize your Agency\n",
        "In this example we'll just use 1 agent. (Yes, you can do that)"
      ],
      "metadata": {
        "id": "NOQkm4qAsu4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agency = Agency([\n",
        "            agent,\n",
        "        ])"
      ],
      "metadata": {
        "id": "vB4-JArrsP-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Define Event Handler\n",
        "The only difference is that you must extend the AgencyEventHandler class, which has 2 additional properties: `agent_name` and `recipient_agent_name`, to get the names of the agents communicating with each other. (See the on_text_created below.)"
      ],
      "metadata": {
        "id": "pHeXRwMHs5N_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import override\n",
        "from agency_swarm import AgencyEventHandler\n",
        "\n",
        "class EventHandler(AgencyEventHandler):\n",
        "    @override\n",
        "    def on_text_created(self, text) -> None:\n",
        "        # get the name of the agent that is sending the message\n",
        "        print(f\"\\n{self.recipient_agent_name} @ {self.agent_name}  > \", end=\"\", flush=True)\n",
        "\n",
        "    @override\n",
        "    def on_text_delta(self, delta, snapshot):\n",
        "        print(delta.value, end=\"\", flush=True)\n",
        "\n",
        "    def on_tool_call_created(self, tool_call):\n",
        "        print(f\"\\n{self.recipient_agent_name} > {tool_call.type}\\n\", flush=True)\n",
        "\n",
        "    def on_tool_call_delta(self, delta, snapshot):\n",
        "        if delta.type == 'code_interpreter':\n",
        "            if delta.code_interpreter.input:\n",
        "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
        "            if delta.code_interpreter.outputs:\n",
        "                print(f\"\\n\\noutput >\", flush=True)\n",
        "                for output in delta.code_interpreter.outputs:\n",
        "                    if output.type == \"logs\":\n",
        "                        print(f\"\\n{output.logs}\", flush=True)\n",
        "\n",
        "    @classmethod\n",
        "    def on_all_streams_end(cls):\n",
        "        print(\"\\n\\nAll streams have ended.\") # Conversation is over and message is returned to the user."
      ],
      "metadata": {
        "id": "OqOmwAOIj47J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, there is an additional class method `on_all_streams_end` which is called when all streams have ended. This method is needed because, unlike in the official documentation, your event handler will be called multiple times and probably by even multiple agents."
      ],
      "metadata": {
        "id": "yXguQLKFtL6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Get Completion"
      ],
      "metadata": {
        "id": "wlXL_iw9tImT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = agency.get_completion_stream(\"Check weather in New York and get nickname of this city.\", event_handler=EventHandler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL7CJ1uPtKbX",
        "outputId": "665fdf3c-5030-4ecf-f9cf-d7ff1464a37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THREAD:[ user -> Agent ]: URL https://platform.openai.com/playground?assistant=asst_rCF4gwi6UmU5IKJawNB6Ghwp&mode=assistant&thread=thread_hPbbXgQyVTBXPFZ2RMoCbJOy\n",
            "\n",
            "Agent > function\n",
            "\n",
            "\n",
            "Agent > function\n",
            "\n",
            "\n",
            "Agent @ User  > The current weather in New York, NY is 75 degrees Fahrenheit, and the nickname of the city is \"The Big Apple.\"\n",
            "\n",
            "All streams have ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OR"
      ],
      "metadata": {
        "id": "19cklCvduY2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simply run gradio demo"
      ],
      "metadata": {
        "id": "vlKmemOquasM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agency.demo_gradio(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0GX81OnwuZ-p",
        "outputId": "49bb3257-c401-4313-b581-30e20d2f28d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://fbc02961f238e66eba.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fbc02961f238e66eba.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Gradio Blocks instance: 6 backend functions\n",
              "-------------------------------------------\n",
              "fn_index=0\n",
              " inputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7d65136bb520>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7d65136bb430>\n",
              " outputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7d65136bb520>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7d65136bb430>\n",
              "fn_index=1\n",
              " inputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7d65136bb520>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7d65136bb430>\n",
              " outputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7d65136bb520>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7d65136bb430>\n",
              "fn_index=2\n",
              " inputs:\n",
              " |-<gradio.components.dropdown.Dropdown object at 0x7d65136bb460>\n",
              " outputs:\n",
              "fn_index=3\n",
              " inputs:\n",
              " |-<gradio.templates.Files object at 0x7d65136e8e50>\n",
              " outputs:\n",
              "fn_index=4\n",
              " inputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7d65136bb520>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7d65136bb430>\n",
              " outputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7d65136bb520>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7d65136bb430>\n",
              "fn_index=5\n",
              " inputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7d65136bb520>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7d65136bb430>\n",
              " outputs:\n",
              " |-<gradio.components.textbox.Textbox object at 0x7d65136bb520>\n",
              " |-<gradio.components.chatbot.Chatbot object at 0x7d65136bb430>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6rE6qinC0Pbh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}