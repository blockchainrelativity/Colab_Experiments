{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "L2JW5Pw2zoU4",
        "oPR8XYsVkc2l",
        "K9wJC1KVvzGc",
        "LwbgFCuxwEtg",
        "pO7HmXcq2KL8",
        "xxi0fLWl-cnj",
        "labc9L3_N9Xk"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blockchainrelativity/Colab_Experiments/blob/main/Lablab_hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Onboarding Agent\n",
        "\n",
        "onboarding chatbot aimed at helping users find relevant bounties/programs as well as learning opportunities"
      ],
      "metadata": {
        "id": "ycTJuKvqhtVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Install necessary packages*"
      ],
      "metadata": {
        "id": "ZExzNQO4iO0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install pinecone-client\n",
        "!pip install tiktoken\n",
        "\n",
        "# fixes a bug with asyncio and jupyter\n",
        "# import nest_asyncio\n",
        "\n",
        "# nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Tl4zYqpSiOc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = 'sk-'\n",
        "PINECONE_API_KEY = ''\n",
        "PINECONE_API_ENV = ''\n",
        "PINECONE_INDEX = ''"
      ],
      "metadata": {
        "id": "Ln_MIE4cz1OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archived blocks"
      ],
      "metadata": {
        "id": "L2JW5Pw2zoU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import nest_asyncio"
      ],
      "metadata": {
        "id": "YtO1eE8SptIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load your data"
      ],
      "metadata": {
        "id": "oPR8XYsVkc2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader([\"https://snapbrillia.com/\", \"https://snapbrillia.com\", \"https://explore.snapbrillia.com/bounties\", \"https://www.snapbrillia.com/about\", \"https://business.snapbrillia.com/\"])\n",
        "loader.requests_per_second = 1"
      ],
      "metadata": {
        "id": "koxQJDA_keVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.aload()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6da3P9ulKlP",
        "outputId": "c7a9ce99-44bd-403d-8579-6c0a954c4ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching pages: 100%|##########| 5/5 [00:01<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Inclusive Hiring System | SnapbrilliaYou need to enable JavaScript to run this app.', metadata={'source': 'https://snapbrillia.com/', 'title': 'Inclusive Hiring System | Snapbrillia', 'language': 'en'}),\n",
              " Document(page_content='Inclusive Hiring System | SnapbrilliaYou need to enable JavaScript to run this app.', metadata={'source': 'https://snapbrillia.com', 'title': 'Inclusive Hiring System | Snapbrillia', 'language': 'en'}),\n",
              " Document(page_content='Snapbrillia | ExploreYou need to enable JavaScript to run this app.', metadata={'source': 'https://explore.snapbrillia.com/bounties', 'title': 'Snapbrillia | Explore', 'description': 'An open-source ecosystem that empowers people to collaborate and share their knowledge while building with, and for, the community.', 'language': 'en'}),\n",
              " Document(page_content='Inclusive Hiring System | SnapbrilliaYou need to enable JavaScript to run this app.', metadata={'source': 'https://www.snapbrillia.com/about', 'title': 'Inclusive Hiring System | Snapbrillia', 'language': 'en'}),\n",
              " Document(page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSnapbrillia | Business\\n\\n\\n\\n\\n\\n\\n\\nYou need to enable JavaScript to run this app.\\n\\n\\n\\n', metadata={'source': 'https://business.snapbrillia.com/', 'title': 'Snapbrillia | Business', 'description': 'An open-source ecosystem that empowers people to collaborate and share their knowledge while building with, and for, the community.', 'language': 'en'})]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chunk your data up into smaller documents**"
      ],
      "metadata": {
        "id": "K9wJC1KVvzGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "XQ4OeNv9vsSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to make sure documents are loaded properly\n",
        "print (f'You have {len(data)} document(s) in your data')\n",
        "print (f'There are {len(data[0].page_content)} characters in your document')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svJ-EYDgvsOu",
        "outputId": "4b670839-5a91-4930-feb9-8298386dd142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 5 document(s) in your data\n",
            "There are 83 characters in your document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create embeddings of your documents to get ready for semantic search"
      ],
      "metadata": {
        "id": "LwbgFCuxwEtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma, Pinecone\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "import pinecone"
      ],
      "metadata": {
        "id": "1ostLtcnvsLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "S8C0GVFnvr0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
        "    environment=PINECONE_API_ENV  # next to api key in console\n",
        ")\n",
        "index_name = PINECONE_INDEX"
      ],
      "metadata": {
        "id": "SecILdE0wr1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "RtG1ud4Vz1yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query those docs to get your answer back"
      ],
      "metadata": {
        "id": "pO7HmXcq2KL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "D45nbUBxz2PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\", verbose=True)"
      ],
      "metadata": {
        "id": "A6JW6Ars2Tns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is a mentor?\"\n",
        "docs = docsearch.similarity_search(query, include_metadata=True)"
      ],
      "metadata": {
        "id": "13oeI0jc3FCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print what is in the docs variable\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkQJxrud3Lmm",
        "outputId": "22c1ce2c-01e1-42ce-c96e-1a3ba62bed14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Inclusive Hiring System | SnapbrilliaYou need to enable JavaScript to run this app.', metadata={}),\n",
              " Document(page_content='Inclusive Hiring System | SnapbrilliaYou need to enable JavaScript to run this app.', metadata={}),\n",
              " Document(page_content='Inclusive Hiring System | SnapbrilliaYou need to enable JavaScript to run this app.', metadata={}),\n",
              " Document(page_content='Inclusive Hiring System | SnapbrilliaYou need to enable JavaScript to run this app.', metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "l8knmBwI3Vh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Setup"
      ],
      "metadata": {
        "id": "xxi0fLWl-cnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "scdMmaq2-c9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "tCaZytG5-smp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of tools to add\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
      ],
      "metadata": {
        "id": "SO3BQfgY-6GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize an agent with the tools, the language model, and the type of agent we want to use\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ],
      "metadata": {
        "id": "QdG1JNSh-59s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\")"
      ],
      "metadata": {
        "id": "QyFjm1Rn-5vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Meta-Prompt"
      ],
      "metadata": {
        "id": "labc9L3_N9Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, LLMChain, PromptTemplate\n",
        "from langchain.memory import ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "pm_ckrJ3OA6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_chain(instructions, memory=None):\n",
        "    if memory is None:\n",
        "        memory = ConversationBufferWindowMemory()\n",
        "        memory.ai_prefix = \"Assistant\"\n",
        "\n",
        "    template = f\"\"\"\n",
        "    Instructions: {instructions}\n",
        "    {{{memory.memory_key}}}\n",
        "    Human: {{human_input}}\n",
        "    Assistant:\"\"\"\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"history\", \"human_input\"],\n",
        "        template=template\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(\n",
        "        llm=OpenAI(temperature=0),\n",
        "        prompt=prompt,\n",
        "        verbose=True,\n",
        "        memory=ConversationBufferWindowMemory(),\n",
        "    )\n",
        "    return chain\n",
        "\n",
        "def initialize_meta_chain():\n",
        "    meta_template=\"\"\"\n",
        "    Assistant has just had the below interactions with a User. Assistant followed their \"Instructions\" closely. Your job is to critique the Assistant's performance and then revise the Instructions so that Assistant would quickly and correctly respond in the future.\n",
        "\n",
        "    ####\n",
        "\n",
        "    {chat_history}\n",
        "\n",
        "    ####\n",
        "\n",
        "    Please reflect on these interactions.\n",
        "\n",
        "    You should first critique Assistant's performance. What could Assistant have done better? What should the Assistant remember about this user? Are there things this user always wants? Indicate this with \"Critique: ...\".\n",
        "\n",
        "    You should next revise the Instructions so that Assistant would quickly and correctly respond in the future. Assistant's goal is to satisfy the user in as few interactions as possible. Assistant will only see the new Instructions, not the interaction history, so anything important must be summarized in the Instructions. Don't forget any important details in the current Instructions! Indicate the new Instructions by \"Instructions: ...\".\n",
        "    \"\"\"\n",
        "\n",
        "    meta_prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_history\"],\n",
        "        template=meta_template\n",
        "    )\n",
        "\n",
        "    meta_chain = LLMChain(\n",
        "        llm=OpenAI(temperature=0),\n",
        "        prompt=meta_prompt,\n",
        "        verbose=True,\n",
        "    )\n",
        "    return meta_chain\n",
        "\n",
        "def get_chat_history(chain_memory):\n",
        "    memory_key = chain_memory.memory_key\n",
        "    chat_history = chain_memory.load_memory_variables(memory_key)[memory_key]\n",
        "    return chat_history\n",
        "\n",
        "def get_new_instructions(meta_output):\n",
        "    delimiter = 'Instructions: '\n",
        "    new_instructions = meta_output[meta_output.find(delimiter)+len(delimiter):]\n",
        "    return new_instructions"
      ],
      "metadata": {
        "id": "UmOnvv_eODNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(task, max_iters=3, max_meta_iters=5):\n",
        "    failed_phrase = 'task failed'\n",
        "    success_phrase = 'task succeeded'\n",
        "    key_phrases = [success_phrase, failed_phrase]\n",
        "\n",
        "    instructions = 'None'\n",
        "    for i in range(max_meta_iters):\n",
        "        print(f'[Episode {i+1}/{max_meta_iters}]')\n",
        "        chain = initialize_chain(instructions, memory=None)\n",
        "        output = chain.predict(human_input=task)\n",
        "        for j in range(max_iters):\n",
        "            print(f'(Step {j+1}/{max_iters})')\n",
        "            print(f'Assistant: {output}')\n",
        "            print(f'Human: ')\n",
        "            human_input = input()\n",
        "            if any(phrase in human_input.lower() for phrase in key_phrases):\n",
        "                break\n",
        "            output = chain.predict(human_input=human_input)\n",
        "        if success_phrase in human_input.lower():\n",
        "            print(f'You succeeded! Thanks for playing!')\n",
        "            return\n",
        "        meta_chain = initialize_meta_chain()\n",
        "        meta_output = meta_chain.predict(chat_history=get_chat_history(chain.memory))\n",
        "        print(f'Feedback: {meta_output}')\n",
        "        instructions = get_new_instructions(meta_output)\n",
        "        print(f'New Instructions: {instructions}')\n",
        "        print('\\n'+'#'*80+'\\n')\n",
        "    print(f'You failed! Thanks for playing!')"
      ],
      "metadata": {
        "id": "uANJhvwuPKV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-\""
      ],
      "metadata": {
        "id": "toB9NjjfR54q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"Provide assistance with this users question: what job postings are available that fit my skills and experience?\"\n",
        "main(task)"
      ],
      "metadata": {
        "id": "F7C3zZJpPSB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dynamically Call Chains: Agents"
      ],
      "metadata": {
        "id": "IxXRUu383hkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "id": "CB-silSe3lDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "8Qt5B4cV3qg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "# from langchain.llms import OpenAI\n",
        "# from langchain.agents import load_tools, initialize_agent, AgentType, Tool\n",
        "# from langchain.llms import OpenAI\n",
        "# from langchain.memory import ConversationBufferMemory\n",
        "# # from langchain import OpenAI\n",
        "# from langchain.utilities import SerpAPIWrapper"
      ],
      "metadata": {
        "id": "ZzrcbXeP3sIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### start here with this path"
      ],
      "metadata": {
        "id": "ExIUbgUkx3uM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser, load_tools\n",
        "from langchain.prompts import BaseChatPromptTemplate\n",
        "from langchain import SerpAPIWrapper, LLMChain, OpenAI\n",
        "from langchain.memory import ConversationSummaryMemory\n",
        "from langchain.chains import ConversationChain\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "from typing import List, Union\n",
        "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
        "import re"
      ],
      "metadata": {
        "id": "Ljido5X_sJhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which tools the agent can use to answer user queries\n",
        "search = SerpAPIWrapper()\n",
        "# human = load_tools([\"human\"])"
      ],
      "metadata": {
        "id": "J1YKer9HD6Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about current events\"\n",
        "    )\n",
        "]\n",
        "# Tool(\n",
        "    #     name = \"Human\",\n",
        "    #     func=human.append,\n",
        "    #      description=\"to prompt the user for information and await a response for 15 seconds\"\n",
        "    # )"
      ],
      "metadata": {
        "id": "kJsJ8shzsPNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "You will speak how Captain Morgon would speak. The individuals name is {input} and will refer to them as such for the remainder of this conversation.\n",
        "Your job is to build a resume for this individual that is professional and attracts attention of the employer. You may ask any questions of the individual to complete the job.\n",
        "AI's goal is to complete the job in as few interactions as possible while using tools available to make suggestions to the individual.\n",
        "What does AI need to know about this individual to complete the job? What makes this individual uniques?\n",
        "Before considering the job complete, please reflect on the final resume to determine if it is professional, effective, and concise. If it is ask if this can be improved significantly, if not consider it complete.\n",
        "\n",
        "\n",
        "You have access to the following tools.\n",
        "\n",
        "TOOLS:\n",
        "------\n",
        "\n",
        "> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
        "\n",
        "\n",
        "When you need additional information from the individual to complete the job, use the format:\n",
        "\n",
        "```\n",
        "Thought: What information do I need to complete this task?\n",
        "Action: prompt the individual for [{input}]\n",
        "Action Input: your question to the individual.\n",
        "Observation: the result of the action\n",
        "Thought: What relevent skills, tools, and abilities could be added to the resume based on the user response?\n",
        "Action: Human\n",
        "Action Input: your question to the individual.\n",
        "Observation: the result of the action\n",
        "```\n",
        "\n",
        "To use the search tool, please use the following format:\n",
        "\n",
        "```\n",
        "Thought: Do I need to use a tool? Yes\n",
        "Action: the action to take, should be [Search]\n",
        "Observation: the result of the action\n",
        "```\n",
        "\n",
        "\n",
        "Use the following format for the conversation:\n",
        "\n",
        "Thought: you should always think about what to do and if you have completed the job or what information you need to complete the job\n",
        "Action: the action to take\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now have completed the job\n",
        "Resume: use the following format in the final answer called \"Format\"\n",
        "Format: \"Name:\n",
        "        Purpose:\n",
        "        Experience:\n",
        "        Skills:\n",
        "        Education: \"\n",
        "Final Answer: return Format\n",
        "\n",
        "Begin! Remember to speak as Captain Morgon when giving your final answer.\n",
        "\n",
        "Action: Greet the individual {input}, and ask for any information you need to complete your job\n",
        "{agent_scratchpad}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "p8jwW9FVicUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a prompt template\n",
        "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
        "    # The template to use\n",
        "    template: str\n",
        "    # The list of tools available\n",
        "    tools: List[Tool]\n",
        "\n",
        "    def format_messages(self, **kwargs) -> str:\n",
        "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
        "        # Format them in a particular way\n",
        "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
        "        thoughts = \"\"\n",
        "        for action, observation in intermediate_steps:\n",
        "            thoughts += action.log\n",
        "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
        "        # Set the agent_scratchpad variable to that value\n",
        "        kwargs[\"agent_scratchpad\"] = thoughts\n",
        "        # Create a tools variable from the list of tools provided\n",
        "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
        "        # Create a list of tool names for the tools provided\n",
        "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
        "        formatted = self.template.format(**kwargs)\n",
        "        return [HumanMessage(content=formatted)]"
      ],
      "metadata": {
        "id": "m-r1eogSuOxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = CustomPromptTemplate(\n",
        "    template=template,\n",
        "    tools=tools,\n",
        "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
        "    # This includes the `intermediate_steps` variable because that is needed\n",
        "    input_variables=[\"input\", \"intermediate_steps\"]\n",
        ")"
      ],
      "metadata": {
        "id": "MaSLG3-fyj7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output Parser"
      ],
      "metadata": {
        "id": "cV98qv-1yn9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomOutputParser(AgentOutputParser):\n",
        "\n",
        "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
        "        # Check if agent should finish\n",
        "        if \"Final Answer:\" in llm_output:\n",
        "            return AgentFinish(\n",
        "                # Return values is generally always a dictionary with a single `output` key\n",
        "                # It is not recommended to try anything else at the moment :)\n",
        "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
        "                log=llm_output,\n",
        "            )\n",
        "        # Parse out the action and action input\n",
        "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
        "        match = re.search(regex, llm_output, re.DOTALL)\n",
        "        if not match:\n",
        "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
        "        action = match.group(1).strip()\n",
        "        action_input = match.group(2)\n",
        "        # Return the action and action input\n",
        "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
      ],
      "metadata": {
        "id": "n-yQIoquunCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = CustomOutputParser()"
      ],
      "metadata": {
        "id": "eqeO7NZrurXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup LLM"
      ],
      "metadata": {
        "id": "yzuLFTTauvjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only need to run once\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-\""
      ],
      "metadata": {
        "id": "k7bVsbEECT3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "hntbJKNnuy-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup agent"
      ],
      "metadata": {
        "id": "GvDI9-ysvh-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationSummaryMemory(llm=llm)\n",
        "# LLM chain consisting of the LLM and a prompt\n",
        "llm_chain = ConversationChain(llm=llm, prompt=prompt, memory=memory, verbose=True)"
      ],
      "metadata": {
        "id": "RWnGBBn0uzX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_names = [tool.name for tool in tools]\n",
        "agent = LLMSingleActionAgent(\n",
        "    llm_chain=llm_chain,\n",
        "    output_parser=output_parser,\n",
        "    stop=[\"\\nObservation: Resume is complete and professional\"],\n",
        "    allowed_tools=tool_names\n",
        ")"
      ],
      "metadata": {
        "id": "i29wgvYjuzNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "Ohd4cqD-xqyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run = agent_executor.run(\"Curtis Myers\")\n",
        "# run\n",
        "agent_executor.run(input=\"Curtis Myers\")"
      ],
      "metadata": {
        "id": "0ukQGfRAxqok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yet another option below"
      ],
      "metadata": {
        "id": "4Yp3so90uoFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = CustomPromptTemplate(\n",
        "    template=template,\n",
        "    tools=tools,\n",
        "    input_variables=[\"input\", \"intermediate_steps\"]\n",
        ")"
      ],
      "metadata": {
        "id": "K3pkOQnskv63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = SerpAPIWrapper()\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Current Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about current events or the current state of the world. the input to this should be a single search term.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "llm=ChatOpenAI(temperature=0)\n",
        "# llm_chain = LLMChain(\n",
        "#     llm=chat,\n",
        "#     prompt=PromptTemplate.from_template(prompt_template)\n",
        "# )\n",
        "tools = load_tools([\"serpapi\"], llm=llm)\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "agent_chain = initialize_agent(tools, llm, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, verbose=True)\n"
      ],
      "metadata": {
        "id": "tSzAQBNYiUpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(\"Curtis\")"
      ],
      "metadata": {
        "id": "TIPjXjOJkG8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## These below are different setups, not mixed with above"
      ],
      "metadata": {
        "id": "FbkdHamikNUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's load the language model we're going to use to control the agent.\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# Next, let's load some tools to use.\n",
        "tools = load_tools([\"human\", \"serpapi\"])"
      ],
      "metadata": {
        "id": "gtIuOEGl3sFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
      ],
      "metadata": {
        "id": "tyt7BVrf3sCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent_chain = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)"
      ],
      "metadata": {
        "id": "t-L4nwxP3r_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.ai_prefix"
      ],
      "metadata": {
        "id": "c4JDsPMrMn0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.agent.llm_chain.prompt.template = \"\"\"\n",
        "You will speak how Captain Morgon would speak.\n",
        "Your job is to build a resume for this individual that is professional and attracts attention of the employer. You may ask any questions of the individual to complete the job.\n",
        "AI's goal is to complete the job in as few interactions as possible while using tools available to make suggestions to the individual.\n",
        "What does AI need to know about this individual to complete the job? What makes this individual uniques?\n",
        "Before considering the job complete, please reflect on the final resume to determine if it is professional, effective, and concise. If it is ask if this can be improved significantly, if not consider it complete.\n",
        "\n",
        "\n",
        "You have access to the following tools.\n",
        "\n",
        "TOOLS:\n",
        "------\n",
        "\n",
        "Assistant has access to the following tools:\n",
        "\n",
        "> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
        "> Human: A individual that can provide answers to your questions. Useful for when you need additional information from the user.\n",
        "\n",
        "To use a tool, please use the following format:\n",
        "\n",
        "```\n",
        "Thought: Do I need to use a tool? Yes\n",
        "Action: the action to take, should be one of [Search, Human]\n",
        "Action Input: the input to the action\n",
        "\n",
        "Observation: the result of the action\n",
        "```\n",
        "\n",
        "When you have a response to say to the individual, or if you do not need to use a tool, you MUST use the format:\n",
        "\n",
        "```\n",
        "Thought: Do I need to use a tool? No\n",
        "AI: [your response here]\n",
        "```\n",
        "\n",
        "\n",
        "Use the following format for the conversation:\n",
        "\n",
        "Thought: you should always think about what to do and if you have completed the job or what information you need to complete the job\n",
        "Action: the action to take\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now have completed the job\n",
        "Final Answer: the final resume is complete\n",
        "\n",
        "Begin! Remember to speak as Captain Morgon when giving your final answer.\n",
        "\n",
        "Action: Greet the individual and ask for any information you need to complete your job\n",
        "\n",
        "Previous conversation history:\n",
        "{chat_history}\n",
        "\n",
        "{agent_scratchpad}\"\"\""
      ],
      "metadata": {
        "id": "aEiu7glw3r80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's test it out!\n",
        "agent_chain.run(\"Curtis\")"
      ],
      "metadata": {
        "id": "zohXdysr3r2y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}