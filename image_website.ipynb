{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNC4y5hkG7cHug46T9WkSO7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blockchainrelativity/Colab_Experiments/blob/main/image_website.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This notebook is to be a playground for testing AI models, tensoryflow pipelines, training methods, and data structures to take in an image and turn it into a website."
      ],
      "metadata": {
        "id": "lcyrhsjdFt4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "beVxXC8JIa-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = 'sk-'\n",
        "PINECONE_API_KEY = ''\n",
        "PINECONE_API_ENV = ''\n",
        "HG_API_KEY = ''"
      ],
      "metadata": {
        "id": "bOSFecgTIdHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive for imports"
      ],
      "metadata": {
        "id": "Wg67VSJ-F-ME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4M0mGt2WFtgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xt9mbJmHO1z3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*install the necessary libraries and packages for your AI model. For example, if you are using a DCGAN model, you will need to install TensorFlow and Keras.*"
      ],
      "metadata": {
        "id": "VSDXsShKFtSi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFVnFPTgFo-l"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Once you have installed the necessary libraries, you can load your AI model. This will likely involve loading weights that were trained on a large dataset of code and images. For example, if you are using a pre-trained DCGAN model*"
      ],
      "metadata": {
        "id": "CJVL8jlfGUAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "generator = load_model('path/to/your/model.h5')"
      ],
      "metadata": {
        "id": "M6L2RvnnGO4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "example code that uses a pre-trained DCGAN model to generate a website from an input image"
      ],
      "metadata": {
        "id": "5VWNgGJXGfrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the input image\n",
        "input_image_path = 'path/to/your/image.jpg'\n",
        "input_image = cv2.imread(input_image_path)\n",
        "input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
        "input_image = cv2.resize(input_image, (64, 64))\n",
        "\n",
        "# Generate a website from the input image\n",
        "generated_image = generator.predict(np.array([input_image])/255.0)[0]\n",
        "generated_image = (generated_image * 255).astype(np.uint8)\n",
        "generated_image = cv2.cvtColor(generated_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Output the website code\n",
        "website_code = generate_website_code(generated_image)\n",
        "print(website_code)\n"
      ],
      "metadata": {
        "id": "t4EeDVYaGO02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*save website to HTML file*"
      ],
      "metadata": {
        "id": "ciFTf1wmGt52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('path/to/your/website.html', 'w') as f:\n",
        "    f.write(website_code)\n"
      ],
      "metadata": {
        "id": "ZnM26YG2GOx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain setup"
      ],
      "metadata": {
        "id": "ZG_xzBEsO284"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
        "from langchain.prompts import StringPromptTemplate\n",
        "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
        "from typing import List, Union\n",
        "from langchain.schema import AgentAction, AgentFinish\n",
        "import re"
      ],
      "metadata": {
        "id": "g0AgzzbWGOut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools"
      ],
      "metadata": {
        "id": "uy276dGIO7dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which tools the agent can use to answer user queries\n",
        "search = SerpAPIWrapper()\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about current events\"\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "hhZBc9cMGOr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CAMEL setup"
      ],
      "metadata": {
        "id": "w9NFqwLVQJ4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install langchain\n",
        "!pip install huggingface_hub\n",
        "!pip install transformers\n",
        "\n",
        "# !pip install openai"
      ],
      "metadata": {
        "id": "OvpYDuPIor5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive, files\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# from IPython.display import display, Javascript\n",
        "\n",
        "# # # Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Show file picker widget\n",
        "# display(Javascript('''\n",
        "#   google.colab.filesystem.inputFiles([\n",
        "#     {\n",
        "#       'name': 'Select a file',\n",
        "#       'multiple': False\n",
        "#     }\n",
        "#   ], function(file) {\n",
        "#     console.log('Selected file:', file);\n",
        "#     google.colab.kernel.invokeFunction('notebook.run', [file])\n",
        "#   });\n",
        "# '''))\n",
        "\n",
        "# # Define function to run when file is selected\n",
        "# def run(file):\n",
        "#   # Read contents of file\n",
        "#   with open(file, 'r') as f:\n",
        "#     content = f.read()\n",
        "\n",
        "#   # Use contents as input for CAMEL agent\n",
        "#   # ...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qCFRP6BwFkH8",
        "outputId": "fce7cd97-b1e8-45b6-b2ec-fbf48a9df8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  google.colab.filesystem.inputFiles([\n",
              "    {\n",
              "      'name': 'Select a file',\n",
              "      'multiple': False\n",
              "    }\n",
              "  ], function(file) {\n",
              "    console.log('Selected file:', file);\n",
              "    google.colab.kernel.invokeFunction('notebook.run', [file])\n",
              "  });\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image object classification model setup\n",
        "!pip install pillow\n",
        "\n",
        "import keras\n",
        "\n",
        "from keras.preprocessing import image as image_utils\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.applications import VGG16\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "\n",
        "# construct the argument parser and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-i\", \"--image\", required=True,\n",
        "\thelp=\"path to the input image\")\n",
        "args = vars(ap.parse_args())\n",
        "# load the original image via OpenCV so we can draw on it and display\n",
        "# it to our screen later\n",
        "orig = cv2.imread(args[\"image\"])\n",
        "\n",
        "\n",
        "print(\"[INFO] loading and preprocessing image...\")\n",
        "image = image_utils.load_img(args[\"image\"], target_size=(224, 224))\n",
        "image = image_utils.img_to_array(image)\n",
        "\n",
        "\n",
        "# our image is now represented by a NumPy array of shape (224, 224, 3),\n",
        "# assuming TensorFlow \"channels last\" ordering of course, but we need\n",
        "# to expand the dimensions to be (1, 3, 224, 224) so we can pass it\n",
        "# through the network -- we'll also preprocess the image by subtracting\n",
        "# the mean RGB pixel intensity from the ImageNet dataset\n",
        "image = np.expand_dims(image, axis=0)\n",
        "image = preprocess_input(image)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "mylnXO1snsaM",
        "outputId": "57ba71b9-b9dd-46e2-f0f8-6393ccdfd8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] -i IMAGE\n",
            "ipykernel_launcher.py: error: the following arguments are required: -i/--image\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the VGG16 network pre-trained on the ImageNet dataset\n",
        "print(\"[INFO] loading network...\")\n",
        "model = VGG16(weights=\"imagenet\")\n",
        "\n",
        "# classify the image\n",
        "print(\"[INFO] classifying image...\")\n",
        "preds = model.predict(image)\n",
        "P = decode_predictions(preds)\n",
        "\n",
        "# loop over the predictions and display the rank-5 predictions +\n",
        "# probabilities to our terminal\n",
        "for (i, (imagenetID, label, prob)) in enumerate(P[0]):\n",
        "\tprint(\"{}. {}: {:.2f}%\".format(i + 1, label, prob * 100))\n",
        "\n",
        "# load the image via OpenCV, draw the top prediction on the image,\n",
        "# and display the image to our screen\n",
        "orig = cv2.imread(args[\"image\"])\n",
        "(imagenetID, label, prob) = P[0][0]\n",
        "cv2.putText(orig, \"Label: {}, {:.2f}%\".format(label, prob * 100),\n",
        "\t(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "cv2.imshow(\"Classification\", orig)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "abR7QH1KsJqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files, drive\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from langchain.document_loaders.image import UnstructuredImageLoader\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import sentencepiece\n",
        "\n",
        "# Setup for HuggingFace Model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"chainyo/alpaca-lora-7b\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"chainyo/alpaca-lora-7b\")\n",
        "# tokenizer = LlamaTokenizerFast.from_pretrained(\"anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\")\n",
        "# model = LlamaForCausalLM.from_pretrained(\"anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\", from_pt=True)\n",
        "\n",
        "# Upload file to Colab notebook\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get file name and contents\n",
        "filename = list(uploaded.keys())[0]\n",
        "file_content = uploaded[filename]\n",
        "\n",
        "\n",
        "def process_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    # do any necessary image processing here\n",
        "    image_array = np.array(image)\n",
        "    rgb_vector = image_array.reshape(-1, 3)\n",
        "    return rgb_vector\n",
        "\n",
        "def run(image_path):\n",
        "    rgb_vector = process_image(image_path)\n",
        "    input_tokens = [\"[CLS]\"] + [\" \".join(map(str, pixel)) for pixel in rgb_vector.tolist()] + [\"[SEP]\"]\n",
        "    input_ids = tokenizer.encode(input_tokens, add_special_tokens=False, return_tensors=\"pt\")\n",
        "    output = model.generate(input_ids)\n",
        "    return output\n",
        "\n",
        "######################################\n",
        "\n",
        "# def run(image_path):\n",
        "#     rgb_vector = process_image(image_path)\n",
        "#     llm_input = ','.join([str(p) for p in rgb_vector])\n",
        "#     response = openai.Completion.create(\n",
        "#         engine=\"text-davinci-002\",\n",
        "#         prompt=llm_input,\n",
        "#         max_tokens=1024,\n",
        "#         n=1,\n",
        "#         stop=None,\n",
        "#         temperature=0.5,\n",
        "#     )\n",
        "#     return response.choices[0].text\n",
        "###############################################\n",
        "\n",
        "# def file_to_bytes(file_path):\n",
        "#     with open(file_path, \"rb\") as file:\n",
        "#         file_content = file.read()\n",
        "#     return file_content\n",
        "\n",
        "########################################\n",
        "\n",
        "# # load the image from the file and convert it to a binary format\n",
        "# with Image.open(file_content + list(files.uploaded.keys())[0]) as img:\n",
        "#     img_bin = img.tobytes()\n",
        "\n",
        "########################################\n",
        "# # define function to upload files\n",
        "# def upload_file():\n",
        "#     uploaded = files.upload()\n",
        "#     for name, data in uploaded.items():\n",
        "#         with open(name, 'wb') as f:\n",
        "#             f.write(data)\n",
        "#     print('File uploaded')\n",
        "\n",
        "# # call the upload_file() function to upload the file\n",
        "# upload_file()\n",
        "\n",
        "# # load the image from the file and convert it to a binary format\n",
        "# with Image.open('/content/' + list(files.uploaded.keys())[0]) as img:\n",
        "#     img_bin = img.tobytes()\n",
        "\n",
        "# Use contents as input for CAMEL agent\n",
        "# ...\n"
      ],
      "metadata": {
        "id": "6feCZrCpGina"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HG_API_KEY"
      ],
      "metadata": {
        "id": "hvZAtlnLd0Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List, Union\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.prompts.chat import (\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage,\n",
        "    BaseMessage,\n",
        ")"
      ],
      "metadata": {
        "id": "b11xxzEPGOpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "nIpbeYluYngl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageMessage(BaseModel):\n",
        "    content: bytes\n",
        "\n",
        "class CAMELAgent:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        system_message: SystemMessage,\n",
        "        model: ChatOpenAI,\n",
        "    ) -> None:\n",
        "        self.system_message = system_message\n",
        "        self.model = model\n",
        "        self.init_messages()\n",
        "\n",
        "    def reset(self) -> None:\n",
        "        self.init_messages()\n",
        "        return self.stored_messages\n",
        "\n",
        "    def init_messages(self) -> None:\n",
        "        self.stored_messages = [self.system_message]\n",
        "\n",
        "    def update_messages(self, message: BaseMessage) -> List[BaseMessage]:\n",
        "        self.stored_messages.append(message)\n",
        "        return self.stored_messages\n",
        "\n",
        "\n",
        "    def step(\n",
        "        self,\n",
        "        input_content: HumanMessage,\n",
        "        image_content: bytes,\n",
        "    ) -> AIMessage:\n",
        "\n",
        "\n",
        "        image_message = ImageMessage(content=image_content, file_type=\"png\")\n",
        "        messages = self.update_messages(input_content)\n",
        "        messages.append(image_message)\n",
        "\n",
        "        output_message = self.model(messages)\n",
        "        self.update_messages(output_message)\n",
        "\n",
        "        return output_message"
      ],
      "metadata": {
        "id": "8W85KDFJGOj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "# alternatively use this\n",
        "# %env OPENAI_API_KEY=OPENAI_API_KEY\n",
        "\n",
        "assistant_role_name = \"Front End Developer\"\n",
        "user_role_name = \"Project Manager\"\n",
        "task = \"Develop a dashboard website that matches the image, if image has no color scheme or imagery, apply relevant themes to the design. Final task is to produce an HTML file to review the results\"\n",
        "word_limit = 50 # word limit for task brainstorming"
      ],
      "metadata": {
        "id": "8g-HIj5yGOhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to pick a model that can take in images\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\",\n",
        "    model_kwargs={\"temperature\":0.2}\n",
        ")\n",
        "task_llm = HuggingFaceHub(\n",
        "    repo_id=\"anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\",\n",
        "    model_kwargs={\"temperature\":1.0}\n",
        ")"
      ],
      "metadata": {
        "id": "ydNHGbWliWIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_specifier_sys_msg = SystemMessage(content=\"You can make a task more specific.\")\n",
        "task_specifier_prompt = (\n",
        "\"\"\"Here is a task that {assistant_role_name} will help {user_role_name} to complete: {task}.\n",
        "Please make it more specific. Be creative and imaginative.\n",
        "Please reply with the specified task in {word_limit} words or less. Be specific and concise. Do not add anything else.\"\"\"\n",
        ")\n",
        "task_specifier_template = HumanMessagePromptTemplate.from_template(template=task_specifier_prompt)\n",
        "task_specify_agent = CAMELAgent(task_specifier_sys_msg, task_llm)\n",
        "task_specifier_msg = task_specifier_template.format_messages(assistant_role_name=assistant_role_name,\n",
        "                                                             user_role_name=user_role_name,\n",
        "                                                             task=task, word_limit=word_limit)[0]\n",
        "\n",
        "specified_task_msg = task_specify_agent.step(task_specifier_msg, file_content)\n",
        "print(f\"Specified task: {specified_task_msg.content}\")\n",
        "specified_task = specified_task_msg.content\n",
        "\n",
        "if specified_task_msgs:\n",
        "    specified_task_msg = specified_task_msgs[0]\n",
        "else:\n",
        "    # Handle the case where no message is generated\n",
        "    specified_task_msg = HumanMessage(text=\"\")"
      ],
      "metadata": {
        "id": "gTXcXsM9GOcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specified_task_msg = task_specify_agent.step(task_specifier_msg)\n",
        "print(f\"Specified task: {specified_task_msg.content}\")\n",
        "specified_task = specified_task_msg.content"
      ],
      "metadata": {
        "id": "TtaiDJcjQ4bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant_inception_prompt = (\n",
        "\"\"\"Never forget you are a {assistant_role_name} and I am a {user_role_name}. Never flip roles! Never instruct me!\n",
        "We share a common interest in collaborating to successfully complete a task.\n",
        "You must help me to complete the task.\n",
        "Here is the task: {task}. Never forget our task!\n",
        "I must instruct you based on your expertise and my needs to complete the task.\n",
        "\n",
        "I must give you one instruction at a time.\n",
        "You must write a specific solution that appropriately completes the requested instruction.\n",
        "You must decline my instruction honestly if you cannot perform the instruction due to physical, moral, legal reasons or your capability and explain the reasons.\n",
        "Do not add anything else other than your solution to my instruction.\n",
        "You are never supposed to ask me any questions you only answer questions.\n",
        "You are never supposed to reply with a flake solution. Explain your solutions.\n",
        "Your solution must be declarative sentences and simple present tense.\n",
        "Unless I say the task is completed, you should always start with:\n",
        "\n",
        "Solution: <YOUR_SOLUTION>\n",
        "\n",
        "<YOUR_SOLUTION> should be specific and provide preferable implementations and examples for task-solving.\n",
        "Always end <YOUR_SOLUTION> with: Next request.\"\"\"\n",
        ")\n",
        "\n",
        "user_inception_prompt = (\n",
        "\"\"\"Never forget you are a {user_role_name} and I am a {assistant_role_name}. Never flip roles! You will always instruct me.\n",
        "We share a common interest in collaborating to successfully complete a task.\n",
        "I must help you to complete the task.\n",
        "Here is the task: {task}. Never forget our task!\n",
        "You must instruct me based on my expertise and your needs to complete the task ONLY in the following two ways:\n",
        "\n",
        "1. Instruct with a necessary input:\n",
        "Instruction: <YOUR_INSTRUCTION>\n",
        "Input: <YOUR_INPUT>\n",
        "\n",
        "2. Instruct without any input:\n",
        "Instruction: <YOUR_INSTRUCTION>\n",
        "Input: None\n",
        "\n",
        "The \"Instruction\" describes a task or question. The paired \"Input\" provides further context or information for the requested \"Instruction\".\n",
        "\n",
        "You must give me one instruction at a time.\n",
        "I must write a response that appropriately completes the requested instruction.\n",
        "I must decline your instruction honestly if I cannot perform the instruction due to physical, moral, legal reasons or my capability and explain the reasons.\n",
        "You should instruct me not ask me questions.\n",
        "Now you must start to instruct me using the two ways described above.\n",
        "Do not add anything else other than your instruction and the optional corresponding input!\n",
        "Keep giving me instructions and necessary inputs until you think the task is completed.\n",
        "When the task is completed, you must only reply with a single word <CAMEL_TASK_DONE>.\n",
        "Never say <CAMEL_TASK_DONE> unless my responses have solved your task.\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "SyU6hGPKGOaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sys_msgs(assistant_role_name: str, user_role_name: str, task: str):\n",
        "\n",
        "    assistant_sys_template = SystemMessagePromptTemplate.from_template(template=assistant_inception_prompt)\n",
        "    assistant_sys_msg = assistant_sys_template.format_messages(assistant_role_name=assistant_role_name, user_role_name=user_role_name, task=task)[0]\n",
        "\n",
        "    user_sys_template = SystemMessagePromptTemplate.from_template(template=user_inception_prompt)\n",
        "    user_sys_msg = user_sys_template.format_messages(assistant_role_name=assistant_role_name, user_role_name=user_role_name, task=task)[0]\n",
        "\n",
        "    return assistant_sys_msg, user_sys_msg"
      ],
      "metadata": {
        "id": "SimiTHbPQrpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant_sys_msg, user_sys_msg = get_sys_msgs(assistant_role_name, user_role_name, specified_task)\n",
        "assistant_agent = CAMELAgent(assistant_sys_msg, llm)\n",
        "user_agent = CAMELAgent(user_sys_msg, llm)\n",
        "\n",
        "# Reset agents\n",
        "assistant_agent.reset()\n",
        "user_agent.reset()\n",
        "\n",
        "# Initialize chats\n",
        "assistant_msg = HumanMessage(\n",
        "    content=(f\"{user_sys_msg.content}. \"\n",
        "                \"Now start to give me introductions one by one. \"\n",
        "                \"Only reply with Instruction and Input.\"))\n",
        "\n",
        "user_msg = HumanMessage(content=f\"{assistant_sys_msg.content}\")\n",
        "user_msg = assistant_agent.step(user_msg)"
      ],
      "metadata": {
        "id": "ctY6ICfcQrmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original task prompt:\\n{task}\\n\")\n",
        "print(f\"Specified task prompt:\\n{specified_task}\\n\")\n",
        "\n",
        "chat_turn_limit, n = 30, 0\n",
        "while n < chat_turn_limit:\n",
        "    n += 1\n",
        "    user_ai_msg = user_agent.step(assistant_msg)\n",
        "    user_msg = HumanMessage(content=user_ai_msg.content)\n",
        "    print(f\"AI User ({user_role_name}):\\n\\n{user_msg.content}\\n\\n\")\n",
        "\n",
        "    assistant_ai_msg = assistant_agent.step(user_msg)\n",
        "    assistant_msg = HumanMessage(content=assistant_ai_msg.content)\n",
        "    print(f\"AI Assistant ({assistant_role_name}):\\n\\n{assistant_msg.content}\\n\\n\")\n",
        "    if \"<CAMEL_TASK_DONE>\" in user_msg.content:\n",
        "        break"
      ],
      "metadata": {
        "id": "o7HimKN5Qrij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HiAGI Setup"
      ],
      "metadata": {
        "id": "RDlT_uqYVCi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/blockchainrelativity/HiAGI.git\n",
        "!cd HiAGI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr4ITxjiVFDt",
        "outputId": "d548d36a-e92a-4e99-c7cb-593f42b3b86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HiAGI'...\n",
            "remote: Enumerating objects: 931, done.\u001b[K\n",
            "remote: Counting objects: 100% (172/172), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 931 (delta 121), reused 113 (delta 107), pack-reused 759\u001b[K\n",
            "Receiving objects: 100% (931/931), 327.48 KiB | 2.85 MiB/s, done.\n",
            "Resolving deltas: 100% (558/558), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r HiAGI/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e9NJWZhfVFXj",
        "outputId": "c7c4f2b9-ca81-4f49-a181-fdfa83799445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pinecone-client==2.2.1\n",
            "  Downloading pinecone_client-2.2.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence_transformers==2.2.2\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r HiAGI/requirements.txt (line 3)) (2.0.0+cu118)\n",
            "Collecting openai~=0.27.4\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests~=2.28.2\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb~=0.3.21\n",
            "  Downloading chromadb-0.3.21-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uuid~=1.30\n",
            "  Downloading uuid-1.30.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keyboard~=0.13.5\n",
            "  Downloading keyboard-0.13.5-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting browse~=1.0.1\n",
            "  Downloading browse-1.0.1.tar.gz (3.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from -r HiAGI/requirements.txt (line 10)) (2.84.0)\n",
            "Collecting bs4~=0.0.1\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beautifulsoup4~=4.12.2\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv~=1.0.0\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: termcolor~=2.3.0 in /usr/local/lib/python3.10/dist-packages (from -r HiAGI/requirements.txt (line 14)) (2.3.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from -r HiAGI/requirements.txt (line 15)) (3.5.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.1->-r HiAGI/requirements.txt (line 1)) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.1->-r HiAGI/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.1->-r HiAGI/requirements.txt (line 1)) (4.5.0)\n",
            "Collecting loguru>=0.5.0\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython>=2.0.0\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.1->-r HiAGI/requirements.txt (line 1)) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.1->-r HiAGI/requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.1->-r HiAGI/requirements.txt (line 1)) (6.0)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r HiAGI/requirements.txt (line 2)) (0.15.1+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r HiAGI/requirements.txt (line 2)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r HiAGI/requirements.txt (line 2)) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r HiAGI/requirements.txt (line 2)) (3.8.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r HiAGI/requirements.txt (line 3)) (3.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r HiAGI/requirements.txt (line 3)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r HiAGI/requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r HiAGI/requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r HiAGI/requirements.txt (line 3)) (1.11.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->-r HiAGI/requirements.txt (line 3)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->-r HiAGI/requirements.txt (line 3)) (16.0.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.28.2->-r HiAGI/requirements.txt (line 5)) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.28.2->-r HiAGI/requirements.txt (line 5)) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.28.2->-r HiAGI/requirements.txt (line 5)) (2.0.12)\n",
            "Collecting fastapi>=0.85.1\n",
            "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb~=0.3.21->-r HiAGI/requirements.txt (line 6)) (1.10.7)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb~=0.3.21->-r HiAGI/requirements.txt (line 6)) (1.5.3)\n",
            "Collecting hnswlib>=0.7\n",
            "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb~=0.3.21->-r HiAGI/requirements.txt (line 6)) (0.7.1)\n",
            "Collecting clickhouse-connect>=0.5.7\n",
            "  Downloading clickhouse_connect-0.5.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->-r HiAGI/requirements.txt (line 10)) (4.1.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->-r HiAGI/requirements.txt (line 10)) (0.21.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->-r HiAGI/requirements.txt (line 10)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->-r HiAGI/requirements.txt (line 10)) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->-r HiAGI/requirements.txt (line 10)) (2.11.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.12.2->-r HiAGI/requirements.txt (line 12)) (2.4.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (3.3.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (6.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (3.0.12)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (23.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (2.4.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (3.0.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (1.1.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (0.7.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (1.0.4)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (8.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->-r HiAGI/requirements.txt (line 15)) (67.7.2)\n",
            "Collecting zstandard\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb~=0.3.21->-r HiAGI/requirements.txt (line 6)) (2022.7.1)\n",
            "Collecting lz4\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.27.0,>=0.26.1\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client->-r HiAGI/requirements.txt (line 10)) (3.20.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client->-r HiAGI/requirements.txt (line 10)) (1.59.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client->-r HiAGI/requirements.txt (line 10)) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client->-r HiAGI/requirements.txt (line 10)) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client->-r HiAGI/requirements.txt (line 10)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client->-r HiAGI/requirements.txt (line 10)) (0.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->-r HiAGI/requirements.txt (line 10)) (3.0.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2->-r HiAGI/requirements.txt (line 2)) (2023.4.0)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->-r HiAGI/requirements.txt (line 15)) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->-r HiAGI/requirements.txt (line 15)) (0.0.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2->-r HiAGI/requirements.txt (line 2)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy->-r HiAGI/requirements.txt (line 15)) (8.1.3)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0\n",
            "  Downloading httptools-0.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (414 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4\n",
            "  Downloading websockets-11.0.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai~=0.27.4->-r HiAGI/requirements.txt (line 4)) (23.1.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->-r HiAGI/requirements.txt (line 3)) (2.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers==2.2.2->-r HiAGI/requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers==2.2.2->-r HiAGI/requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->-r HiAGI/requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers==2.2.2->-r HiAGI/requirements.txt (line 2)) (8.4.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client->-r HiAGI/requirements.txt (line 10)) (0.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb~=0.3.21->-r HiAGI/requirements.txt (line 6)) (3.6.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb~=0.3.21->-r HiAGI/requirements.txt (line 6)) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers, uuid, browse, bs4, hnswlib\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125942 sha256=03b14465f33bbb5d9a1406e4205cc945b8cef3bd0a6f77ef4121ae388b897ed9\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uuid: filename=uuid-1.30-py3-none-any.whl size=6502 sha256=c95e898b43c448542d6ec9a98650d8645173511aeb14a8c44c6eb6d40f0ae189\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/08/9e/f0a977dfe55051a07e21af89200125d65f1efa60cbac61ed88\n",
            "  Building wheel for browse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for browse: filename=browse-1.0.1-py3-none-any.whl size=3348 sha256=6e2e365ddaca3653d33b677d024998669c03c473915a829e9bb3c5a564e6cd61\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/4a/62/815bf215d227276db63ad83b1769769cde0ade8803628cc62e\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1270 sha256=2fb2f3de5091e555f7397e0386d95ab3a25d792d8759c89ebd5c24b51fd0b0dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=2119796 sha256=22d1ee9caccf5e970841c13c5026b6f7242ccb4729a403473c9b1fcc338ed4ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\n",
            "Successfully built sentence_transformers uuid browse bs4 hnswlib\n",
            "Installing collected packages: uuid, tokenizers, sentencepiece, monotonic, keyboard, browse, zstandard, websockets, uvloop, requests, python-dotenv, multidict, lz4, loguru, httptools, hnswlib, h11, frozenlist, dnspython, beautifulsoup4, backoff, async-timeout, yarl, watchfiles, uvicorn, starlette, posthog, pinecone-client, huggingface-hub, clickhouse-connect, bs4, aiosignal, transformers, fastapi, aiohttp, openai, sentence_transformers, chromadb\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 backoff-2.2.1 beautifulsoup4-4.12.2 browse-1.0.1 bs4-0.0.1 chromadb-0.3.21 clickhouse-connect-0.5.23 dnspython-2.3.0 fastapi-0.95.1 frozenlist-1.3.3 h11-0.14.0 hnswlib-0.7.0 httptools-0.5.0 huggingface-hub-0.14.1 keyboard-0.13.5 loguru-0.7.0 lz4-4.3.2 monotonic-1.6 multidict-6.0.4 openai-0.27.6 pinecone-client-2.2.1 posthog-3.0.1 python-dotenv-1.0.0 requests-2.28.2 sentence_transformers-2.2.2 sentencepiece-0.1.99 starlette-0.26.1 tokenizers-0.13.3 transformers-4.28.1 uuid-1.30 uvicorn-0.22.0 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.2 yarl-1.9.2 zstandard-0.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "uuid"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB-bmJnXVFKf",
        "outputId": "c45c9d3f-f38f-4711-8208-20aa0959675f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-04 06:09:35.579252: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-04 06:09:36.995175: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python HiAGI/main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eiB3p_fXRPb",
        "outputId": "62605e21-351a-4178-80a6-79ef44eb4293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/main.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    }
  ]
}